{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer, pipeline, CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://sigongan-3f44b-default-rtdb.firebaseio.com/archive.json').json()\n",
    "list = [value for key, value in r.items()]\n",
    "df = pd.DataFrame(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g_spread import *\n",
    "gsp = GSpread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp.updateByDf(df[['imageUrl', 'description']], [4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d98ebe6316450dac285af4e74c9fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6668de45794b258d4d5b14d40cc6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/982M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86c104654aa4130869d85308f19283f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/241 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0aeeac429742fa8c3461d9114d4b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1113f7565abd4753b81056374080a7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c555226c98e449f5b3c2357e92c29ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432c419ccdba445a9e542317d9fffe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3021805c5a343569130e60524137814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jusang/Library/Python/3.9/lib/python/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/Users/jusang/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_to_text = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "df['captioning'] = df.apply(lambda x: image_to_text(x.imageUrl)[0]['generated_text'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp.updateByDf(df[['captioning']], [4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier1(url, label=['real photo', 'document']):\n",
    "    image = Image.open(requests.get(url, stream=True).raw)\n",
    "    inputs = processor(text=label, images=image, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image # this is the image-text similarity score\n",
    "    probs = logits_per_image.softmax(dim=1) #\n",
    "    return torch.max(probs, dim=1).indices.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class1'] = df.imageUrl.apply(lambda x: classifier1(x, label=['picture', 'document']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsp.updateByDf(df[['class1']], [4, 4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QA Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai.api_key = os.getenv('API_KEY')\n",
    "\n",
    "params = {\n",
    "    'engine': 'text-davinci-003',\n",
    "    'max_tokens': 1000,\n",
    "    'temperature': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to sigongan-ai v0.0.1.\n",
      "\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      " isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      " isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      " isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      "3 isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      "3 isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      "3 isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      "1 isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      " isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      " isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      "e isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      "asdf isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      "we isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      " isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n",
      " isn't a selectable mode. Try again\n",
      "Please select the mode\n",
      "1: Brief description 2: QA mode 3: Quit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Select mode\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPlease select the mode\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m1: Brief description 2: QA mode 3: Quit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m()\n\u001b[1;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m2\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m3\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode):\n\u001b[1;32m     11\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m isn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt a selectable mode. Try again\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[1;32m   1192\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[1;32m   1193\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1194\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1195\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1196\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1232\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1233\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m   1235\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1236\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "context = ''\n",
    "imageUrl = \"https://firebasestorage.googleapis.com/v0/b/sigongan-3f44b.appspot.com/o/images%2Fscaled_1678243980217.jpg?alt=media&token=76d08213-9929-4f73-bc77-c48ffd639079\"\n",
    "\n",
    "print(\"Welcome to sigongan-ai v0.0.1.\\n\")\n",
    "\n",
    "while True:\n",
    "    # Select mode\n",
    "    print(\"Please select the mode\\n1: Brief description 2: QA mode 3: Quit\")\n",
    "    mode = input()\n",
    "    if ('1' not in mode or '2' not in mode or '3' not in mode):\n",
    "        print(f\"{mode} isn't a selectable mode. Try again\")\n",
    "        continue\n",
    "    \n",
    "    if('3' in mode): break\n",
    "    \n",
    "    # mode 1\n",
    "    if('1' in mode):\n",
    "        while True:\n",
    "            print('You selected mode 1. Preparing for description...')\n",
    "            print('\"Description\"')\n",
    "            continue\n",
    "        \n",
    "        # mode 2\n",
    "    elif(mode in '2'):\n",
    "        while True:\n",
    "            print(f'Question: \\n')\n",
    "            question = input()\n",
    "            prompt = f\"Question: {question}. Plase give me the most detailed answer for this question. Answer:\"\n",
    "            response = openai.Completion.create(engine=params['engine'], prompt=prompt,temperature=params['temperature'], max_tokens=params['max_tokens'])\n",
    "            answer = response.choices[0].text.strip()\n",
    "            print(f\"Answer: {answer}\\n Ask again: 1\\nQuit: else\")\n",
    "            mode = input()\n",
    "            if ('1' in mode): continue\n",
    "            else: break            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
